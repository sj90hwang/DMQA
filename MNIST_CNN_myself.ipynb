{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "\n",
    "import torch.nn.init\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)   #random value를 잡아주는? 항상 같은 random이 나오는 걸로 설명은 되어있으나 완벽하게 이해 못함 질문1\n",
    "if device == 'cuda' : \n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "# data 다운 되게 만드는 보안 헤더 코드???? 질문2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters 정의해둠 > data loader에 써야되니까 batch size등\n",
    "learning_rate = 0.001\n",
    "training_epochs =15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset =mnist_train,\n",
    "                                         batch_size = batch_size,\n",
    "                                          shuffle = True,\n",
    "                                          drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module) :\n",
    "    \n",
    "    def __init__(self) :\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1,32,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        # fully connected layer\n",
    "        self.fc = nn.Linear(7*7*64,10,bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight) #초기화진행\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        \n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_epch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-8a2f1a06a6ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mlist_epch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mlist_train_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'list_epch' is not defined"
     ]
    }
   ],
   "source": [
    "#training\n",
    "total_batch = len(data_loader)\n",
    "\n",
    "#final epoch loss accuracy report를 위한 리스트를 만든다!\n",
    "list_epoch = [] \n",
    "list_train_loss = []\n",
    "list_acc = []\n",
    "list_acc_epoch = []\n",
    "\n",
    "for epoch in range(training_epochs) :\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for X, Y in data_loader :\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        \n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()  \n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost/total_batch \n",
    "        \n",
    "        list_epoch.append(i)\n",
    "        list_train_loss.append(loss.detach().numpy())\n",
    "        \n",
    "    print('[Epoch:{}] cost = {}'.format(epoch+1, avg_cost))\n",
    "    \n",
    "print('Learning Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9884999990463257\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():    #학습안할꺼니까 선언\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test),1,28,28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "    \n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy : ',accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data image of shape 28 * 28 = 784\n",
    "linear = torch.nn.Linear(784, 10, bias=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  7\n",
      "Prediction:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "# ====== Loss Fluctuation ====== #\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot(list_epoch, list_train_loss, label='train_loss')\n",
    "ax1.plot(list_epoch, list_val_loss, '--', label='val_loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "ax1.set_title('epoch vs loss')\n",
    "\n",
    "# ====== Metric Fluctuation ====== #\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.plot(list_acc_epoch, list_acc, marker='x', label='Accuracy metric')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.set_ylabel('Acc')\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "ax2.set_title('epoch vs Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
