{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "\n",
    "import torch.nn.init\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)   #random value를 잡아주는? 항상 같은 random이 나오는 걸로 설명은 되어있으나 완벽하게 이해 못함 질문1\n",
    "if device == 'cuda' : \n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "# data 다운 되게 만드는 보안 헤더 코드???? 질문2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters 정의해둠 > data loader에 써야되니까 batch size등\n",
    "learning_rate = 0.001\n",
    "training_epochs =15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset =mnist_train,\n",
    "                                         batch_size = batch_size,\n",
    "                                          shuffle = True,\n",
    "                                          drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module) :\n",
    "    \n",
    "    def __init__(self) :\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1,32,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        # fully connected layer\n",
    "        self.fc = nn.Linear(7*7*64,10,bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight) #초기화진행\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        \n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000002516FEC57B0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:1] cost = 0.2239377647638321\n",
      "[Epoch:2] cost = 0.0621107779443264\n",
      "[Epoch:3] cost = 0.044862788170576096\n",
      "[Epoch:4] cost = 0.03549288958311081\n",
      "[Epoch:5] cost = 0.028979092836380005\n",
      "[Epoch:6] cost = 0.024833615869283676\n",
      "[Epoch:7] cost = 0.020771212875843048\n",
      "[Epoch:8] cost = 0.018137114122509956\n",
      "[Epoch:9] cost = 0.01498472597450018\n",
      "[Epoch:10] cost = 0.012506215833127499\n",
      "[Epoch:11] cost = 0.010574866086244583\n",
      "[Epoch:12] cost = 0.009698821231722832\n",
      "[Epoch:13] cost = 0.008231629617512226\n",
      "[Epoch:14] cost = 0.007171574980020523\n",
      "[Epoch:15] cost = 0.006446900311857462\n",
      "Learning Finished\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "total_batch = len(data_loader)\n",
    "\n",
    "for epoch in range(training_epochs) :\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for X, Y in data_loader :\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        \n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost/total_batch \n",
    "        \n",
    "    print('[Epoch:{}] cost = {}'.format(epoch+1, avg_cost))\n",
    "    \n",
    "print('Learning Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9860999584197998\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():    #학습안할꺼니까 선언\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test),1,28,28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "    \n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy : ',accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data image of shape 28 * 28 = 784\n",
    "linear = torch.nn.Linear(784, 10, bias=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.08389999717473984\n",
      "Label:  1\n",
      "Prediction:  8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
